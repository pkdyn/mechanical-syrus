{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4ZzpNCHf+fE5WXnJf2mr3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkdyn/mechanical-syrus/blob/main/mech_syrus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6nM3_ZHX_c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQnQteTK7UL",
        "outputId": "f5f810f6-f2b6-4186-8f3c-dd497deb863f"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://github.com/pkdyn/mechanical-syrus/archive/refs/heads/main.zip \n",
        "!unzip -q /content/main.zip\n",
        "!rm /content/main.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-22 16:45:59--  https://github.com/pkdyn/mechanical-syrus/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/pkdyn/mechanical-syrus/zip/refs/heads/main [following]\n",
            "--2021-07-22 16:46:00--  https://codeload.github.com/pkdyn/mechanical-syrus/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ]  25.92K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-07-22 16:46:00 (416 KB/s) - ‘main.zip’ saved [26537]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb4ICmSfPB3M"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "max_sequence_len = 6\n",
        "sentences=[]\n",
        "alltext=[]\n",
        "data = open('/content/mechanical-syrus-main/Moral-Sayings-of-Publius.txt').read()\n",
        "corpus = data.lower()\n",
        "alltext.append(corpus)\n",
        "words = corpus.split(\" \")\n",
        "range_size = len(words)-max_sequence_len\n",
        "for i in range(0, range_size):\n",
        "\tthissentence=\"\"\n",
        "\tfor word in range(0, max_sequence_len-1):\n",
        "\t\tword = words[i+word]\n",
        "\t\tthissentence = thissentence + word\n",
        "\t\tthissentence = thissentence + \" \"\n",
        "\tsentences.append(thissentence)\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_size=3200\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok, split=\" \", char_level=False)\n",
        "tokenizer.fit_on_texts(alltext)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in sentences:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m97Zm07ANMM2",
        "outputId": "3d983fd7-45d3-4eba-9e4e-317748dfdc4a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 16, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "history = model.fit(xs, ys, epochs=50)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1421/1421 [==============================] - 26s 14ms/step - loss: 6.0805 - accuracy: 0.0598\n",
            "Epoch 2/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 5.6101 - accuracy: 0.0803\n",
            "Epoch 3/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 5.3470 - accuracy: 0.0968\n",
            "Epoch 4/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 5.0978 - accuracy: 0.1162\n",
            "Epoch 5/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 4.8725 - accuracy: 0.1409\n",
            "Epoch 6/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 4.6621 - accuracy: 0.1598\n",
            "Epoch 7/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 4.4698 - accuracy: 0.1775\n",
            "Epoch 8/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 4.2911 - accuracy: 0.1957\n",
            "Epoch 9/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 4.1229 - accuracy: 0.2119\n",
            "Epoch 10/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.9608 - accuracy: 0.2284\n",
            "Epoch 11/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.8124 - accuracy: 0.2445\n",
            "Epoch 12/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.6744 - accuracy: 0.2614\n",
            "Epoch 13/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.5455 - accuracy: 0.2775\n",
            "Epoch 14/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.4217 - accuracy: 0.2950\n",
            "Epoch 15/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.3084 - accuracy: 0.3101\n",
            "Epoch 16/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.2029 - accuracy: 0.3253\n",
            "Epoch 17/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.1023 - accuracy: 0.3401\n",
            "Epoch 18/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.0086 - accuracy: 0.3542\n",
            "Epoch 19/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.9176 - accuracy: 0.3708\n",
            "Epoch 20/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.8328 - accuracy: 0.3853\n",
            "Epoch 21/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.7505 - accuracy: 0.4021\n",
            "Epoch 22/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.6768 - accuracy: 0.4146\n",
            "Epoch 23/50\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.6064 - accuracy: 0.4256\n",
            "Epoch 24/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.5390 - accuracy: 0.4399\n",
            "Epoch 25/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.4750 - accuracy: 0.4512\n",
            "Epoch 26/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.4091 - accuracy: 0.4668\n",
            "Epoch 27/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.3521 - accuracy: 0.4774\n",
            "Epoch 28/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.2971 - accuracy: 0.4898\n",
            "Epoch 29/50\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.2424 - accuracy: 0.5001\n",
            "Epoch 30/50\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.1920 - accuracy: 0.5080\n",
            "Epoch 31/50\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.1439 - accuracy: 0.5188\n",
            "Epoch 32/50\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.0981 - accuracy: 0.5289\n",
            "Epoch 33/50\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.0546 - accuracy: 0.5384\n",
            "Epoch 34/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.0134 - accuracy: 0.5464\n",
            "Epoch 35/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.9724 - accuracy: 0.5537\n",
            "Epoch 36/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.9355 - accuracy: 0.5618\n",
            "Epoch 37/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.9001 - accuracy: 0.5697\n",
            "Epoch 38/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.8675 - accuracy: 0.5751\n",
            "Epoch 39/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.8322 - accuracy: 0.5833\n",
            "Epoch 40/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.8035 - accuracy: 0.5908\n",
            "Epoch 41/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.7775 - accuracy: 0.5941\n",
            "Epoch 42/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.7444 - accuracy: 0.6034\n",
            "Epoch 43/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.7165 - accuracy: 0.6081\n",
            "Epoch 44/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.6869 - accuracy: 0.6149\n",
            "Epoch 45/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6652 - accuracy: 0.6176\n",
            "Epoch 46/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6437 - accuracy: 0.6228\n",
            "Epoch 47/50\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6216 - accuracy: 0.6288\n",
            "Epoch 48/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.6075 - accuracy: 0.6305\n",
            "Epoch 49/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.5771 - accuracy: 0.6367\n",
            "Epoch 50/50\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.5610 - accuracy: 0.6421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzcDMVruUJkh",
        "outputId": "f761a385-cdb6-4e3a-bc2f-766561b8cf6e"
      },
      "source": [
        "seed_text = \"The ego is the enemy\"\n",
        "\n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "#print(model.predict(token_list))  \n",
        "predicted = model.predict_classes(token_list)\n",
        "pred_classes=model.predict(token_list)\n",
        "print(pred_classes.reshape(-1)[predicted])\n",
        "print(predicted)\n",
        "for word, index in tokenizer.word_index.items():\n",
        "\tif index == predicted:\n",
        "\t\tprint(word)\n",
        "\t\tbreak"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.4721238]\n",
            "[27]\n",
            "and\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}