{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvTee0afhEfl5ra0rXf4hg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkdyn/mechanical-syrus/blob/main/mech_syrus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6nM3_ZHX_c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQnQteTK7UL",
        "outputId": "f5f810f6-f2b6-4186-8f3c-dd497deb863f"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://github.com/pkdyn/mechanical-syrus/archive/refs/heads/main.zip \n",
        "!unzip -q /content/main.zip\n",
        "!rm /content/main.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-22 16:45:59--  https://github.com/pkdyn/mechanical-syrus/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/pkdyn/mechanical-syrus/zip/refs/heads/main [following]\n",
            "--2021-07-22 16:46:00--  https://codeload.github.com/pkdyn/mechanical-syrus/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ]  25.92K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-07-22 16:46:00 (416 KB/s) - ‘main.zip’ saved [26537]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb4ICmSfPB3M"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "max_sequence_len = 6\n",
        "sentences=[]\n",
        "alltext=[]\n",
        "data = open('/content/mechanical-syrus-main/Moral-Sayings-of-Publius.txt').read()\n",
        "corpus = data.lower()\n",
        "alltext.append(corpus)\n",
        "words = corpus.split(\" \")\n",
        "range_size = len(words)-max_sequence_len\n",
        "for i in range(0, range_size):\n",
        "\tthissentence=\"\"\n",
        "\tfor word in range(0, max_sequence_len-1):\n",
        "\t\tword = words[i+word]\n",
        "\t\tthissentence = thissentence + word\n",
        "\t\tthissentence = thissentence + \" \"\n",
        "\tsentences.append(thissentence)\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_size=3200\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok, split=\" \", char_level=False)\n",
        "tokenizer.fit_on_texts(alltext)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in sentences:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m97Zm07ANMM2",
        "outputId": "44f127d1-0c81-4be4-cb57-46998f0f0ba2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 16, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "history = model.fit(xs, ys, epochs=100)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1421/1421 [==============================] - 25s 13ms/step - loss: 6.0703 - accuracy: 0.0593\n",
            "Epoch 2/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 5.6109 - accuracy: 0.0805\n",
            "Epoch 3/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 5.3550 - accuracy: 0.0990\n",
            "Epoch 4/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 5.0958 - accuracy: 0.1205\n",
            "Epoch 5/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 4.8342 - accuracy: 0.1497\n",
            "Epoch 6/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 4.6026 - accuracy: 0.1714\n",
            "Epoch 7/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 4.3989 - accuracy: 0.1894\n",
            "Epoch 8/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 4.2063 - accuracy: 0.2104\n",
            "Epoch 9/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 4.0370 - accuracy: 0.2247\n",
            "Epoch 10/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.8793 - accuracy: 0.2420\n",
            "Epoch 11/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 3.7327 - accuracy: 0.2576\n",
            "Epoch 12/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 3.6007 - accuracy: 0.2727\n",
            "Epoch 13/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.4736 - accuracy: 0.2876\n",
            "Epoch 14/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.3516 - accuracy: 0.3041\n",
            "Epoch 15/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.2370 - accuracy: 0.3205\n",
            "Epoch 16/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.1303 - accuracy: 0.3375\n",
            "Epoch 17/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 3.0305 - accuracy: 0.3524\n",
            "Epoch 18/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.9348 - accuracy: 0.3674\n",
            "Epoch 19/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.8471 - accuracy: 0.3838\n",
            "Epoch 20/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.7646 - accuracy: 0.3969\n",
            "Epoch 21/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.6852 - accuracy: 0.4109\n",
            "Epoch 22/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.6110 - accuracy: 0.4239\n",
            "Epoch 23/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.5425 - accuracy: 0.4360\n",
            "Epoch 24/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.4735 - accuracy: 0.4531\n",
            "Epoch 25/100\n",
            "1421/1421 [==============================] - 19s 13ms/step - loss: 2.4118 - accuracy: 0.4625\n",
            "Epoch 26/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.3490 - accuracy: 0.4738\n",
            "Epoch 27/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.2960 - accuracy: 0.4856\n",
            "Epoch 28/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.2428 - accuracy: 0.4981\n",
            "Epoch 29/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 2.1926 - accuracy: 0.5062\n",
            "Epoch 30/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 2.1394 - accuracy: 0.5181\n",
            "Epoch 31/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 2.0985 - accuracy: 0.5268\n",
            "Epoch 32/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 2.0570 - accuracy: 0.5317\n",
            "Epoch 33/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 2.0141 - accuracy: 0.5435\n",
            "Epoch 34/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.9729 - accuracy: 0.5540\n",
            "Epoch 35/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.9415 - accuracy: 0.5588\n",
            "Epoch 36/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.9037 - accuracy: 0.5668\n",
            "Epoch 37/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.8734 - accuracy: 0.5714\n",
            "Epoch 38/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.8395 - accuracy: 0.5796\n",
            "Epoch 39/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.8093 - accuracy: 0.5864\n",
            "Epoch 40/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.7797 - accuracy: 0.5920\n",
            "Epoch 41/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.7499 - accuracy: 0.5983\n",
            "Epoch 42/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.7239 - accuracy: 0.6029\n",
            "Epoch 43/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6991 - accuracy: 0.6084\n",
            "Epoch 44/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6759 - accuracy: 0.6133\n",
            "Epoch 45/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6522 - accuracy: 0.6180\n",
            "Epoch 46/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.6313 - accuracy: 0.6221\n",
            "Epoch 47/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.6052 - accuracy: 0.6290\n",
            "Epoch 48/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.5858 - accuracy: 0.6331\n",
            "Epoch 49/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.5683 - accuracy: 0.6369\n",
            "Epoch 50/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.5503 - accuracy: 0.6417\n",
            "Epoch 51/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.5321 - accuracy: 0.6442\n",
            "Epoch 52/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.5089 - accuracy: 0.6486\n",
            "Epoch 53/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.4957 - accuracy: 0.6530\n",
            "Epoch 54/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.4828 - accuracy: 0.6557\n",
            "Epoch 55/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.4636 - accuracy: 0.6586\n",
            "Epoch 56/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.4496 - accuracy: 0.6628\n",
            "Epoch 57/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.4337 - accuracy: 0.6666\n",
            "Epoch 58/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.4209 - accuracy: 0.6675\n",
            "Epoch 59/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.4055 - accuracy: 0.6702\n",
            "Epoch 60/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3951 - accuracy: 0.6738\n",
            "Epoch 61/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3776 - accuracy: 0.6773\n",
            "Epoch 62/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3691 - accuracy: 0.6773\n",
            "Epoch 63/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3567 - accuracy: 0.6800\n",
            "Epoch 64/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3452 - accuracy: 0.6855\n",
            "Epoch 65/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.3388 - accuracy: 0.6885\n",
            "Epoch 66/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3299 - accuracy: 0.6894\n",
            "Epoch 67/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3124 - accuracy: 0.6921\n",
            "Epoch 68/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.3048 - accuracy: 0.6915\n",
            "Epoch 69/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.2967 - accuracy: 0.6953\n",
            "Epoch 70/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2866 - accuracy: 0.6976\n",
            "Epoch 71/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.2748 - accuracy: 0.6991\n",
            "Epoch 72/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.2674 - accuracy: 0.7025\n",
            "Epoch 73/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2606 - accuracy: 0.7017\n",
            "Epoch 74/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2486 - accuracy: 0.7057\n",
            "Epoch 75/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2426 - accuracy: 0.7066\n",
            "Epoch 76/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.2333 - accuracy: 0.7106\n",
            "Epoch 77/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2272 - accuracy: 0.7092\n",
            "Epoch 78/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.2191 - accuracy: 0.7121\n",
            "Epoch 79/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2161 - accuracy: 0.7122\n",
            "Epoch 80/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.2037 - accuracy: 0.7162\n",
            "Epoch 81/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1935 - accuracy: 0.7178\n",
            "Epoch 82/100\n",
            "1421/1421 [==============================] - 19s 14ms/step - loss: 1.1935 - accuracy: 0.7180\n",
            "Epoch 83/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1861 - accuracy: 0.7186\n",
            "Epoch 84/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1791 - accuracy: 0.7202\n",
            "Epoch 85/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1763 - accuracy: 0.7202\n",
            "Epoch 86/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1682 - accuracy: 0.7232\n",
            "Epoch 87/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1604 - accuracy: 0.7232\n",
            "Epoch 88/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1582 - accuracy: 0.7242\n",
            "Epoch 89/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1522 - accuracy: 0.7263\n",
            "Epoch 90/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1491 - accuracy: 0.7262\n",
            "Epoch 91/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1410 - accuracy: 0.7292\n",
            "Epoch 92/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1366 - accuracy: 0.7293\n",
            "Epoch 93/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1356 - accuracy: 0.7286\n",
            "Epoch 94/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1283 - accuracy: 0.7292\n",
            "Epoch 95/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1222 - accuracy: 0.7298\n",
            "Epoch 96/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1182 - accuracy: 0.7319\n",
            "Epoch 97/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1189 - accuracy: 0.7305\n",
            "Epoch 98/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1087 - accuracy: 0.7340\n",
            "Epoch 99/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1114 - accuracy: 0.7341\n",
            "Epoch 100/100\n",
            "1421/1421 [==============================] - 20s 14ms/step - loss: 1.1021 - accuracy: 0.7334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzcDMVruUJkh",
        "outputId": "338f901d-4c5b-4f16-f019-b7b1fa2ca4da"
      },
      "source": [
        "seed_text = \"Ego is the enemy\"\n",
        "seed_text1= \"Stillness is the key\"\n",
        "seed_text2= \"The obstacle is the way\"\n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "#print(model.predict(token_list))  \n",
        "predicted = model.predict_classes(token_list)\n",
        "pred_classes=model.predict(token_list)\n",
        "print(pred_classes.reshape(-1)[predicted])\n",
        "print(predicted)\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index == predicted:\n",
        "    print(word)\n",
        "    break"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.16343364]\n",
            "[6]\n",
            "of\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CecxgTxqLgc1",
        "outputId": "f590da24-efff-4647-94c9-fbbe77d7b1ae"
      },
      "source": [
        "\n",
        "def gen(seed_text,next_words ):\n",
        "  for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict_classes(token_list, verbose=0)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == predicted:\n",
        "        output_word = word\n",
        "        break\n",
        "    seed_text += \" \" + output_word\n",
        "  print(seed_text)\n",
        "gen(seed_text, 20)\n",
        "gen(seed_text1, 9)\n",
        "gen(seed_text2, 14)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ego is the enemy of the proud let a fool hold his tongue and he who can play the hypocrite can soonest injure his\n",
            "Stillness is the key of the people's treasure he who can get more\n",
            "The obstacle is the way for it one will agree with you sooner than it to it the defect\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}